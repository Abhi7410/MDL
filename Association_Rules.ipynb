{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "08d9a2ab",
   "metadata": {},
   "source": [
    "## Association \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82bf321d",
   "metadata": {},
   "source": [
    "Association rule learning is a type of unsupervised learning technique that checks for the dependency of one data item on another data item and maps accordingly so that it can be more profitable. It tries to find some interesting relations or associations among the variables of dataset. It is based on different rules to discover the interesting relations between variables in the database."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56256bd0",
   "metadata": {},
   "source": [
    "Association rule learning can be divided into three types of algorithms:\n",
    "\n",
    "- Apriori\n",
    "- Eclat\n",
    "- F-P Growth Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4ac9ee",
   "metadata": {},
   "source": [
    "- IF A   then B\n",
    "\n",
    "Here the If element is called antecedent, and then statement is called as Consequent. \n",
    "\n",
    "These types of relationships where we can find out some association or relation between two items is known as <b>single cardinality</b>. It is all about creating rules, and if the number of items increases, then cardinality also increases accordingly. So, to measure the associations between thousands of data items, there are several metrics. These metrics are given below:\n",
    "\n",
    "- Support\n",
    "- Confidence\n",
    "- Lift"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a1cd03",
   "metadata": {},
   "source": [
    "#### Support\n",
    "Support is the frequency of A or how frequently an item appears in the dataset. It is defined as the fraction of the transaction T that contains the itemset X. If there are X datasets, then for transactions T, it can be written as:\n",
    " \n",
    "Support = Freq(X)/T\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a0eb6d7",
   "metadata": {},
   "source": [
    "#### Confidence\n",
    "Confidence indicates how often the rule has been found to be true. Or how often the items X and Y occur together in the dataset when the occurrence of X is already given. It is the ratio of the transaction that contains X and Y to the number of records that contain X.\n",
    "\n",
    "Confidence = Freq(X,Y)/Freq(X)\n",
    "\n",
    "It is like Bayes theorem in probability "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa3bc262",
   "metadata": {},
   "source": [
    "#### Lift\n",
    "It is the strength of any rule, which can be defined as below formula:\n",
    "\n",
    "Lift = Supp(X,Y)/Supp(X).Supp(Y)\n",
    "\n",
    "It is the ratio of the observed support measure and expected support if X and Y are independent of each other. It has three possible values:\n",
    "\n",
    "- If Lift= 1: The probability of occurrence of antecedent and consequent is independent of each other.\n",
    "- Lift>1: It determines the degree to which the two itemsets are dependent to each other.\n",
    "- Lift<1: It tells us that one item is a substitute for other items, which means one item has a negative effect on another."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac66832f",
   "metadata": {},
   "source": [
    "### Apriori Algorithm\n",
    "\n",
    "Apriori algorithm refers to an algorithm that is used in mining frequent products sets and relevant association rules. Generally, the apriori algorithm operates on a database containing a huge number of transactions. For example, the items customers but at a Big Bazar.\n",
    "\n",
    "Apriori algorithm helps the customers to buy their products with ease and increases the sales performance of the particular store.\n",
    "\n",
    "The Apriori algorithm uses frequent itemsets to generate association rules, and it is designed to work on the databases that contain transactions. With the help of these association rule, it determines how strongly or how weakly two objects are connected. This algorithm uses a breadth-first search and Hash Tree to calculate the itemset associations efficiently. It is the iterative process for finding the frequent itemsets from the large dataset.\n",
    "\n",
    "**What is Frequent Itemset?**\n",
    "\n",
    "Frequent itemsets are those items whose support is greater than the threshold value or user-specified minimum support. It means if A & B are the frequent itemsets together, then individually A and B should also be the frequent itemset.\n",
    "\n",
    "\n",
    "Below are the steps for the apriori algorithm:\n",
    "\n",
    "- Step-1: Determine the support of itemsets in the transactional database, and select the minimum support and confidence.\n",
    "\n",
    "- Step-2: Take all supports in the transaction with higher support value than the minimum or selected support value.\n",
    "\n",
    "- Step-3: Find all the rules of these subsets that have higher confidence value than the threshold or minimum confidence.\n",
    "\n",
    "- Step-4: Sort the rules as the decreasing order of lift.\n",
    "\n",
    "After checking every rule , we get the final candidate set and then find confidence of all subsets of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48de9d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementation \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from apyori import apriori\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "621ba6fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shrimp</td>\n",
       "      <td>almonds</td>\n",
       "      <td>avocado</td>\n",
       "      <td>vegetables mix</td>\n",
       "      <td>green grapes</td>\n",
       "      <td>whole weat flour</td>\n",
       "      <td>yams</td>\n",
       "      <td>cottage cheese</td>\n",
       "      <td>energy drink</td>\n",
       "      <td>tomato juice</td>\n",
       "      <td>low fat yogurt</td>\n",
       "      <td>green tea</td>\n",
       "      <td>honey</td>\n",
       "      <td>salad</td>\n",
       "      <td>mineral water</td>\n",
       "      <td>salmon</td>\n",
       "      <td>antioxydant juice</td>\n",
       "      <td>frozen smoothie</td>\n",
       "      <td>spinach</td>\n",
       "      <td>olive oil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>burgers</td>\n",
       "      <td>meatballs</td>\n",
       "      <td>eggs</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chutney</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>turkey</td>\n",
       "      <td>avocado</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mineral water</td>\n",
       "      <td>milk</td>\n",
       "      <td>energy bar</td>\n",
       "      <td>whole wheat rice</td>\n",
       "      <td>green tea</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0          1           2                 3             4   \\\n",
       "0         shrimp    almonds     avocado    vegetables mix  green grapes   \n",
       "1        burgers  meatballs        eggs               NaN           NaN   \n",
       "2        chutney        NaN         NaN               NaN           NaN   \n",
       "3         turkey    avocado         NaN               NaN           NaN   \n",
       "4  mineral water       milk  energy bar  whole wheat rice     green tea   \n",
       "\n",
       "                 5     6               7             8             9   \\\n",
       "0  whole weat flour  yams  cottage cheese  energy drink  tomato juice   \n",
       "1               NaN   NaN             NaN           NaN           NaN   \n",
       "2               NaN   NaN             NaN           NaN           NaN   \n",
       "3               NaN   NaN             NaN           NaN           NaN   \n",
       "4               NaN   NaN             NaN           NaN           NaN   \n",
       "\n",
       "               10         11     12     13             14      15  \\\n",
       "0  low fat yogurt  green tea  honey  salad  mineral water  salmon   \n",
       "1             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "2             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "3             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "4             NaN        NaN    NaN    NaN            NaN     NaN   \n",
       "\n",
       "                  16               17       18         19  \n",
       "0  antioxydant juice  frozen smoothie  spinach  olive oil  \n",
       "1                NaN              NaN      NaN        NaN  \n",
       "2                NaN              NaN      NaN        NaN  \n",
       "3                NaN              NaN      NaN        NaN  \n",
       "4                NaN              NaN      NaN        NaN  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "store_data = pd.read_csv('store_data.csv',header= None)\n",
    "store_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "286f786b",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_records = len(store_data)\n",
    "records = []\n",
    "for i in range(0,num_records):\n",
    "    records.append([str(store_data.values[i,j]) for j in range(0,20)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f517e646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "association_rules = apriori(records,min_support = 0.0053,min_confidence = 0.20,min_lift = 3,min_length = 2)\n",
    "association_results = list(association_rules)\n",
    "print(len(association_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4b7cc0",
   "metadata": {},
   "source": [
    "- transactions: A list of transactions.\n",
    "- min_support= To set the minimum support float value. Here we have used 0.003 that is calculated by taking 3 - --transactions per customer each week to the total number of transactions.\n",
    "- min_confidence: To set the minimum confidence value. Here we have taken 0.2. It can be changed as per the business problem.\n",
    "- min_lift= To set the minimum lift value.\n",
    "- min_length= It takes the minimum number of products for the association.\n",
    "- max_length = It takes the maximum number of products for the association."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d99d7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               T1                    T2  Support Confidence     Lift\n",
      "0        escalope  mushroom cream sauce  0.00573    0.30069  3.79083\n",
      "1           pasta              escalope  0.00586    0.37288  4.70081\n",
      "2     ground beef         herb & pepper  0.01599    0.32345  3.29199\n",
      "3     ground beef          tomato sauce  0.00533    0.37735  3.84065\n",
      "4       olive oil     whole wheat pasta  0.00799    0.27149  4.12241\n",
      "5       chocolate                shrimp  0.00533    0.23255  3.25451\n",
      "6        escalope                   nan  0.00573    0.30069  3.79083\n",
      "7           pasta              escalope  0.00586    0.37288  4.70081\n",
      "8     ground beef             spaghetti  0.00866    0.31100  3.16532\n",
      "9   mineral water                shrimp  0.00719    0.30508  3.20061\n",
      "10      olive oil             spaghetti  0.00573    0.20574  3.12402\n",
      "11      spaghetti                shrimp  0.00599    0.21531  3.01314\n",
      "12       tomatoes             spaghetti  0.00666    0.23923  3.49804\n",
      "13    ground beef             spaghetti  0.00533    0.32258  3.28314\n",
      "14    ground beef         herb & pepper  0.00666    0.39062  3.97568\n",
      "15    ground beef         herb & pepper  0.01599    0.32345  3.29199\n",
      "16    ground beef             spaghetti  0.00639    0.39344  4.00435\n",
      "17    ground beef                   nan  0.00533    0.37735  3.84065\n",
      "18    ground beef             spaghetti  0.00599    0.52325  3.00531\n",
      "19           milk             spaghetti  0.00719    0.20300  3.08250\n",
      "20      olive oil                   nan  0.00799    0.27149  4.13077\n",
      "21      chocolate                shrimp  0.00533    0.23255  3.26059\n",
      "22    ground beef             spaghetti  0.00866    0.31100  3.16532\n",
      "23  mineral water                shrimp  0.00719    0.30508  3.20061\n",
      "24      olive oil             spaghetti  0.00573    0.20574  3.13036\n",
      "25      spaghetti                shrimp  0.00599    0.21531  3.01878\n",
      "26       tomatoes             spaghetti  0.00666    0.23923  3.49804\n",
      "27    ground beef             spaghetti  0.00533    0.32258  3.28314\n",
      "28    ground beef         herb & pepper  0.00666    0.39062  3.97568\n",
      "29    ground beef             spaghetti  0.00639    0.39344  4.00435\n",
      "30    ground beef             spaghetti  0.00599    0.52325  3.00531\n",
      "31           milk             spaghetti  0.00719    0.20300  3.08876\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for item in association_results:\n",
    "    pair = item[0]\n",
    "    items = [x for x in pair]\n",
    "    \n",
    "    value0 = str(items[0])\n",
    "    value1 = str(items[1])\n",
    "    value2 = str(item[1])[:7]\n",
    "    value3 = str(item[2][0][2])[:7]\n",
    "    value4 = str(item[2][0][3])[:7]\n",
    "    \n",
    "    rows = (value0,value1,value2,value3,value4)\n",
    "    results.append(rows)\n",
    "label = ['T1','T2','Support','Confidence','Lift']\n",
    "    \n",
    "store_sugg = pd.DataFrame.from_records(results,columns = label)\n",
    "print(store_sugg)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a412f07",
   "metadata": {},
   "source": [
    "## Types of Association Rules\n",
    "\n",
    "1. **Boolean Association Rules** : If a rule involves associations between the presence or absence of items, it is a Boolean association rule. For example, the following three rules are Boolean association rules obtained from market basket analysis.\n",
    "\n",
    "2. Hierarchical Rules \n",
    "\n",
    "3. **Quantitative and Categorical Rules** Quantitative association rules involve numeric attributes that have an implicit ordering among values (e.g., age). If a rule describes associations between quantitative items or attributes, then it is a quantitative association rule. In these rules, quantitative values for items or attributes are partitioned into intervals. Following rule is considered a quantitative association rule.\n",
    "\n",
    "4. Cyclic/Periodic Rules\n",
    "\n",
    "5. **Constrained Rules** In order to make the mining process more efficient rule based constraint mining : - allows users to describe the rules that they would like to uncover. - provides a sophisticated mining query optimizer that can be used to exploit the constraints specified by the user. - encourages interactive exploratory mining and analysis.\n",
    "\n",
    "6. **Sequential Rules :** A sequential rule is a rule of the form X -> Y  where X and Y are sets of items (itemsets).  A rule X ->Y is interpreted as if  items in X occurs (in any order), then it will be followed by the items in Y (in any order).  For example, consider the rule {a} -> {e,f}. It means that if a customer buy item “a”, then the customer will later buy the items “e” and “f”.  But the order among items in {e,f} is not important. This means that a customer may buy “e” before “f” or “f” before “e”.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76ea7e29",
   "metadata": {},
   "source": [
    "### ECLAT algorithm\n",
    "The ECLAT algorithm stands for Equivalence Class Clustering and bottom-up Lattice Traversal. It is one of the popular methods of Association Rule mining. It is a more efficient and scalable version of the Apriori algorithm. While the Apriori algorithm works in a horizontal sense imitating the Breadth-First Search of a graph, the ECLAT algorithm works in a vertical manner just like the Depth-First Search of a graph. This vertical approach of the ECLAT algorithm makes it a faster algorithm than the Apriori algorithm.\n",
    "\n",
    "**How the algorithm work? :**\n",
    "The basic idea is to use Transaction Id Sets(tidsets) intersections to compute the support value of a candidate and avoiding the generation of subsets which do not exist in the prefix tree. In the first call of the function, all single items are used along with their tidsets. Then the function is called recursively and in each recursive call, each item-tidset pair is verified and combined with other item-tidset pairs. This process is continued until no candidate item-tidset pairs can be combined.\n",
    "\n",
    "https://www.geeksforgeeks.org/ml-eclat-algorithm/#:~:text=The%20ECLAT%20algorithm%20stands%20for,version%20of%20the%20Apriori%20algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c446dbf",
   "metadata": {},
   "source": [
    "### FP Growth Algorithm\n",
    "\n",
    "This algorithm is an improvement to the Apriori method. A frequent pattern is generated without the need for candidate generation. FP growth algorithm represents the database in the form of a tree called a frequent pattern tree or FP tree.\n",
    "\n",
    "This tree structure will maintain the association between the itemsets. The database is fragmented using one frequent item. This fragmented part is called “pattern fragment”. The itemsets of these fragmented patterns are analyzed. Thus with this method, the search for frequent itemsets is reduced comparatively.\n",
    "\n",
    "https://www.softwaretestinghelp.com/fp-growth-algorithm-data-mining/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
